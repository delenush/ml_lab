{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import Sequentia\n",
    "import regex as re \n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_matrix(X):\n",
    "    tok = Tokenizer(num_words=1000)\n",
    "    tok.fit_on_texts(X)\n",
    "    sequences = tok.texts_to_sequences(X)\n",
    "    return sequence.pad_sequences(sequences,maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data, len_set):\n",
    "    data = pd.read_csv(data,encoding='latin-1', header = None)\n",
    "    lab0 = data[data[0] == 0][:len_set]\n",
    "    data[0][data[0] == 4] = 1\n",
    "    lab4 = data[data[0] == 1][:len_set]\n",
    "    data = pd.concat([lab0,lab4])\n",
    "    data = data.reset_index()\n",
    "    data.pop('index')\n",
    "    tweets = []\n",
    "    for row in range(len(data)):\n",
    "        tweets.append((data[5][row], data[0][row]))\n",
    "    filtered_tweets = []\n",
    "    X = []\n",
    "    y = []\n",
    "    porter=PorterStemmer()\n",
    "    sc = StandardScaler()\n",
    "    for (words, sentiment) in tweets:\n",
    "        \n",
    "        words_filtered = [e.lower() for e in words.split() if len(e) >= 3]\n",
    "        words_filtered = list(filter(lambda x: not x.startswith('http') and not x.startswith('@'), words_filtered))\n",
    "        words_filtered = [re.sub(r\"\\p{P}+\", \"\", word) for word in words_filtered ]\n",
    "        stem_sentence=[]\n",
    "        for word in words_filtered:\n",
    "            stem_sentence.append(porter.stem(word))\n",
    "        \n",
    "        X.append(stem_sentence)\n",
    "        y.append(sentiment)\n",
    "    \n",
    "    X = get_X_matrix(X)\n",
    "    return sc.fit_transform(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessing_data('train_data.csv',100000)\n",
    "X_test, y_test = preprocessing_data('test_data.csv', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.6931 - accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.6924 - accuracy: 0.5155\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.6922 - accuracy: 0.5166\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.6919 - accuracy: 0.5197\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.6919 - accuracy: 0.5197\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.6918 - accuracy: 0.5195\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.6920 - accuracy: 0.5190\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.6919 - accuracy: 0.5186\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.6920 - accuracy: 0.5180\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.6921 - accuracy: 0.5182\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.7855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.665386974811554, 0.785515308380127]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Input(shape=(100,)),\n",
    "      tf.keras.layers.Embedding(1000, 32, input_length=100),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])\n",
    "model.compile(optimizer=RMSprop(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=100, shuffle = True, verbose=1)\n",
    "model.evaluate(X_test, y_test, batch_size=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
